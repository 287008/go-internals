# 2.1 map的实现

Go中的map在底层是用[hash表](../go/src/pkg/runtime/hashmap.c)实现的。

## 数据结构
hash表的数据结构中一些关键的域如下所示：

```C
	struct Hmap
	{
		uint8   B;
		uint16  bucketsize;   // 每个桶的大小

		byte    *buckets;     // 2^B个Buckets的数组
		byte    *oldbuckets;  // 前一个buckets，只有当正在扩容时才不为空
	};
```

上在给出的结体中只是Hmap的部分的域。需要注意到的是，这里直接使用的是Bucket的数组，而不是Bucket*指针的数组。这意味着，第一个Bucket和后面溢出链的Bucket分配有些不同。第一个个Bucket是用的一段连续的内存空间，而后面溢出链的Bucket的空间是使用mallocgc分配的。

这个hash结构使用的是一个可扩展哈希的算法，由hash值mod当前hash表大小决定某一个值属于哪个桶，而hash表大小是2的指数，即上面结构体中的2^B。每次扩容，会增大到上次大小的两倍。结构体中有一个buckets和一个oldbuckets是用来实现增量扩容的。正常情况下直接使用buckets，而oldbuckets为空，。如果当前哈希表正在扩容中，则oldbuckets不为空，并且buckets大小是oldbuckets大小的两倍。

具体的Bucket结构如下所示：

```C
	struct Bucket
	{
		uint8  tophash[BUCKETSIZE]; // hash值的高8位....低位从bucket的array定位到bucket
		Bucket *overflow;           // 溢出桶链表，如果有
		byte   data[1];             // BUCKETSIZE keys followed by BUCKETSIZE values
	};
```

其中BUCKETSIZE是用宏定义的8，每个bucket中存放最多8个key/value对, 如果多于8个，那么会申请一个新的bucket，并将它与之前的bucket链起来。

按key的类型不同会采用相应不同的hash算法得到key的hash值。将hash值的低位当作bucket数组的index，找到key所在的bucket。将hash的高8位存储在了bucket的tophash中。注意，这里高8位不是用来当作在key/value在bucket内部的offset的，而是作为一个主键，在查找时是对tophash数组的每一项进行顺序匹配的，先比较hash值高位与bucket的tophash[i]是否相等，如果相等则再比较bucket的第i个的key与所给的key是否相等。如果相等，则返回其对应的value，反之，在overflow buckets中按照上述方法继续寻找。

整个hash的存储如下图所示(临时先采用了XX同学画的图)：

注意一个细节是Bucket中key/value的放置顺序，是将keys放在一起，values放在一起，为什么不将key和对应的value放在一起呢？那么存储结构将变成key1/value1/key2/value2… 设想如果是这样的一个map[int64]int8,并且考虑字节对齐，会产生很多的对齐，浪费存储空间。不得不说通过上述的一个小细节，可以看出go在设计上的深思熟虑。

## 增量扩容
大家都知道hash的本质就是以空间换时间，访问速度是直接跟填充因子相关的，所以当哈希表太满之后就需要进行扩容。

对于某个哈希值hash，则一般情况下(hash mod X)不等于(hash mod Y)，所以扩容之后要重新计算每一项在哈希表中的新位置。假设扩容前的哈希表大小为2^B，扩容之后的大小为2^(B+1)，哈希表大小为2的指数倍，每次扩容都变为原来大小的两倍，则有(hash mod 2^B)等于(hash & (2^B-1))。这样可以简化运算，避免了取余操作。

当hash表扩容之后，需要将那些旧的pair重新哈希到新的table上(源代码中中称之为evacuate)， 这个工作并没有在扩容之后，一次性完成，而是逐步的完成（在insert和remove时每次搬移1-2个pair）。

为什么会增量扩容呢？主要是缩短map容器的响应时间。假如我们直接将map用作某个响应实时性要求非常高的web应用存储，如果不采用增量扩容，map里面存储的元素很多之后，扩容时系统就会卡往，导致较长一段时间内无法响应。不过本质上还是将总的扩容时间分摊到了每一次哈希操作上面。

需要注意的是:那些已经evacuated的buckets会被mark标记：
#define evacuated(b) (((uintptr)(b)->overflow & 1) != 0)
在evacuate的过程中，一个old bucket中的pairs会被重新散列到2个不同的new bucket中:
if (hashValue & oldTableCapacity == 0) {    newBuckets = oldBuckets;} else {    newBuckets[i + oldTableCapacity] = oldBuckets;}

正是由于这个工作是逐渐完成的，这样就会导致一部分数据在old table中，一部分在new table中， 所以对于hash table的insert, remove, lookup操作的处理逻辑产生影响。

扩容的填充因子是多少呢？如果grow的太频繁，会造成空间的利用率很低， 如果很久才grow，会形成很多的overflow buckets，查找的效率也会下降。 这个平衡点如何选取呢(在go中，这个平衡点是有一个宏控制的(#define LOAD 6.5), 它的意思是这样的，如果table中元素的个数 > table中能容纳的元素的个数, 那么就触发一次grow动作。那么这个6.5是怎么得到的呢？原来这个值来源于作者的一个测试程序，遗憾的是没能找到相关的源码，不过作者给出了测试的结果：

	        LOAD    %overflow  bytes/entry     hitprobe    missprobe
	        4.00         2.13        20.77         3.00         4.00
	        4.50         4.05        17.30         3.25         4.50
	        5.00         6.85        14.77         3.50         5.00
	        5.50        10.55        12.94         3.75         5.50
	        6.00        15.27        11.67         4.00         6.00
	        6.50        20.90        10.79         4.25         6.50
	        7.00        27.14        10.15         4.50         7.00
	        7.50        34.03         9.73         4.75         7.50
	        8.00        41.10         9.40         5.00         8.00
	
	 %overflow   = percentage of buckets which have an overflow bucket
	 bytes/entry = overhead bytes used per key/value pair
	 hitprobe    = # of entries to check when looking up a present key
	 missprobe   = # of entries to check when looking up an absent key

可以看出作者取了一个相对适中的值。

## 查找过程

## 插入过程分析

## 性能问题
目前这种实现中有几个做的不算很好的地方。一个是HMap中是Bucket的数组，而不是Bucket指针的数组。

lookup:
根据key算出hash值。
如果存在old table, 首先在old table中查找，如果找到的bucket已经evacuated，转到步骤3。 反之，返回其对应的value。
在new table中查找对应的value。
insert:
根据key算出hash值，进而得出对应的bucket。
如果bucket在old table中，将其重新散列到new table中。
在bucket中，查找空闲的位置，如果已经存在需要插入的key，更新其对应的value。
根据table中元素的个数，判断是否grow table。
如果对应的bucket已经full，重新申请新的bucket作为overbucket。
将key/value pair插入到bucket中。
remove:
根据key算出hash值，进而得出对应的bucket。
如果bucket在old table中，将其重新散列到new table中。
在对应的bucket以及它的overbuckets中，查找对应的pair并将其删除 （这里的删除，只是将位置信息清0:
b->tophash = 0;h->count--;
而具体的内存释放，会根据flag去处理:
if((h->flags & CanFreeKey) != 0) {    runtime·free(k);}if((h->flags & IndirectValue) != 0) {    runtime·free(v);}
这里有2个TODO:
将多个几乎要empty的bucket合并。
如果table中元素很少，考虑shrink table。(毕竟现在的实现只是单纯的grow)
